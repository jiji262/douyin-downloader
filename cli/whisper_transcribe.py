#!/usr/bin/env python3
"""
whisper_transcribe.py â€” å¯¹ douyin-downloader ä¸‹è½½çš„è§†é¢‘è¿›è¡Œ Whisper è¯­éŸ³è¯†åˆ«

å®‰è£…:
  pip install openai-whisper rich
  # ffmpeg: conda install -c conda-forge ffmpeg  æˆ–æ”¾ ffmpeg.exe åˆ°åŒç›®å½•

ç”¨æ³•:
  python whisper_transcribe.py                          # æ‰«æ ./Downloaded/ ä¸‹æ‰€æœ‰mp4
  python whisper_transcribe.py -d ./Downloaded/          # æŒ‡å®šç›®å½•
  python whisper_transcribe.py -f video.mp4              # å•ä¸ªæ–‡ä»¶
  python whisper_transcribe.py -d ./Downloaded/ -m medium # ç”¨mediumæ¨¡å‹
  python whisper_transcribe.py -d ./Downloaded/ --srt     # åŒæ—¶è¾“å‡ºSRT
  python whisper_transcribe.py --skip-existing --sc       # è·³è¿‡å·²æœ‰ + ç¹è½¬ç®€
"""
import argparse
import os
import shutil
import subprocess
import sys
import tempfile
from pathlib import Path
from typing import Optional

from rich.console import Console
from rich.progress import (
    BarColumn,
    Progress,
    SpinnerColumn,
    TaskProgressColumn,
    TextColumn,
    TimeElapsedColumn,
)
from rich.table import Table
from rich.panel import Panel
from rich.text import Text

console = Console()

# â”€â”€ é¢œè‰²ä¸»é¢˜ (åŒºåˆ«äº douyin-downloader çš„ cyan/magenta) â”€â”€
THEME = {
    "accent":  "bright_green",
    "banner":  "bold bright_green",
    "info":    "dodger_blue1",
    "success": "green",
    "warning": "yellow",
    "error":   "red",
    "dim":     "dim white",
    "file":    "bright_cyan",
    "model":   "orchid",
}


# ============================================================
# TranscribeDisplay â€” rich è¿›åº¦æ˜¾ç¤º
# ============================================================
class TranscribeDisplay:
    def __init__(self):
        self.console = console
        self._progress_ctx: Optional[Progress] = None
        self._progress: Optional[Progress] = None
        self._overall_id: Optional[int] = None
        self._file_id: Optional[int] = None
        self._file_index = 0
        self._file_total = 0
        self._stats = {"success": 0, "failed": 0, "skipped": 0}

    # â”€â”€ banner â”€â”€
    def show_banner(self):
        banner = Text()
        banner.append("  ğŸ™  Whisper è§†é¢‘è½¬å½•å·¥å…·\n", style="bold bright_green")
        banner.append("  â”€â”€ Video â†’ Text via OpenAI Whisper â”€â”€", style="dim bright_green")
        panel = Panel(banner, border_style="bright_green", expand=False, padding=(0, 2))
        self.console.print(panel)
        self.console.print()

    # â”€â”€ progress lifecycle â”€â”€
    def start_session(self, total: int):
        self._file_total = total
        self._file_index = 0
        self._stats = {"success": 0, "failed": 0, "skipped": 0}

        self._progress_ctx = Progress(
            SpinnerColumn(style="bright_green"),
            TextColumn("[progress.description]{task.description}"),
            BarColumn(bar_width=30, complete_style="bright_green", finished_style="green"),
            TaskProgressColumn(),
            TimeElapsedColumn(),
            TextColumn("[dim]{task.fields[detail]}"),
            console=self.console,
            transient=True,
            refresh_per_second=6,
        )
        self._progress = self._progress_ctx.__enter__()
        self._overall_id = self._progress.add_task(
            "[bright_green]æ€»ä½“è¿›åº¦[/]",
            total=max(total, 1),
            completed=0,
            detail=f"å…± {total} ä¸ªè§†é¢‘",
        )

    def stop_session(self):
        if self._file_id is not None and self._progress:
            self._progress.remove_task(self._file_id)
            self._file_id = None
        if self._progress_ctx is not None:
            self._progress_ctx.__exit__(None, None, None)
        self._progress_ctx = None
        self._progress = None
        self._overall_id = None

    # â”€â”€ per-file â”€â”€
    def start_file(self, index: int, name: str):
        self._file_index = index
        if self._file_id is not None and self._progress:
            self._progress.remove_task(self._file_id)
        if not self._progress:
            return
        self._file_id = self._progress.add_task(
            self._file_desc("æå–éŸ³é¢‘"),
            total=4,  # æå–éŸ³é¢‘ â†’ è¯†åˆ« â†’ è½¬æ¢ â†’ ä¿å­˜
            completed=0,
            detail=self._shorten(name, 50),
        )

    def advance_file(self, step: str, detail: str = ""):
        if not self._progress or self._file_id is None:
            return
        self._progress.advance(self._file_id, 1)
        self._progress.update(
            self._file_id,
            description=self._file_desc(step),
            detail=detail,
        )

    def complete_file(self, status: str, detail: str = ""):
        if status in self._stats:
            self._stats[status] += 1
        if self._progress:
            if self._file_id is not None:
                self._progress.update(
                    self._file_id, completed=4,
                    description=self._file_desc("å®Œæˆ" if status == "success" else "è·³è¿‡" if status == "skipped" else "å¤±è´¥"),
                    detail=detail,
                )
                self._progress.remove_task(self._file_id)
                self._file_id = None
            if self._overall_id is not None:
                self._progress.advance(self._overall_id, 1)
                self._progress.update(
                    self._overall_id,
                    detail=f"âœ“{self._stats['success']}  âœ—{self._stats['failed']}  âŠ˜{self._stats['skipped']}",
                )

    # â”€â”€ summary table â”€â”€
    def show_summary(self):
        table = Table(
            title="Transcription Summary",
            show_header=True,
            header_style=f"bold {THEME['accent']}",
            border_style=THEME["accent"],
        )
        table.add_column("Metric", style=THEME["info"])
        table.add_column("Count", justify="right", style=THEME["success"])

        total = self._stats["success"] + self._stats["failed"] + self._stats["skipped"]
        table.add_row("Total", str(total))
        table.add_row("Success", str(self._stats["success"]))
        table.add_row("Failed", str(self._stats["failed"]))
        table.add_row("Skipped", str(self._stats["skipped"]))
        if total > 0:
            rate = self._stats["success"] / total * 100
            table.add_row("Success Rate", f"{rate:.1f}%")

        self.console.print()
        self.console.print(table)

    # â”€â”€ logging â”€â”€
    def info(self, msg: str):
        self._out().print(f"[{THEME['info']}]â„¹[/] {msg}")

    def success(self, msg: str):
        self._out().print(f"[{THEME['success']}]âœ“[/] {msg}")

    def warning(self, msg: str):
        self._out().print(f"[{THEME['warning']}]âš [/] {msg}")

    def error(self, msg: str):
        self._out().print(f"[{THEME['error']}]âœ—[/] {msg}")

    def dep_ok(self, name: str, detail: str = ""):
        self._out().print(f"  [{THEME['success']}]âœ“[/] {name}  [{THEME['dim']}]{detail}[/]")

    def dep_fail(self, name: str, hint: str):
        self._out().print(f"  [{THEME['error']}]âœ—[/] {name}  [{THEME['dim']}]{hint}[/]")

    # â”€â”€ internal â”€â”€
    def _file_desc(self, step: str) -> str:
        return f"[{THEME['accent']}]{self._file_index}/{self._file_total}[/] Â· {step}"

    def _out(self) -> Console:
        return self._progress.console if self._progress else self.console

    @staticmethod
    def _shorten(text: str, max_len: int = 50) -> str:
        t = (text or "").strip()
        return t if len(t) <= max_len else f"{t[:max_len - 3]}..."


display = TranscribeDisplay()


# ============================================================
# æ ¸å¿ƒåŠŸèƒ½
# ============================================================
def find_ffmpeg():
    p = shutil.which("ffmpeg")
    if p:
        return p
    local = Path(__file__).parent / "ffmpeg.exe"
    if local.exists():
        return str(local)
    try:
        import imageio_ffmpeg
        return imageio_ffmpeg.get_ffmpeg_exe()
    except ImportError:
        pass
    return None


def extract_audio(video_path, audio_path, ffmpeg_path="ffmpeg"):
    cmd = [
        ffmpeg_path, "-i", str(video_path),
        "-vn", "-acodec", "pcm_s16le", "-ar", "16000", "-ac", "1",
        str(audio_path), "-y", "-loglevel", "quiet",
    ]
    result = subprocess.run(cmd, capture_output=True)
    return result.returncode == 0 and Path(audio_path).exists()


def _format_srt_time(seconds):
    h, r = divmod(seconds, 3600)
    m, r = divmod(r, 60)
    s = int(r)
    ms = int((r - s) * 1000)
    return f"{int(h):02d}:{int(m):02d}:{s:02d},{ms:03d}"


def transcribe_file(video_path, model, ffmpeg_path, output_formats, language, converter):
    video_path = Path(video_path)
    stem = video_path.stem
    out_dir = video_path.parent
    txt_path = out_dir / f"{stem}.transcript.txt"
    srt_path = out_dir / f"{stem}.transcript.srt"

    tmpdir = tempfile.mkdtemp(prefix="whisper_")
    try:
        # Step 1: æå–éŸ³é¢‘
        audio_path = os.path.join(tmpdir, "audio.wav")
        if not extract_audio(video_path, audio_path, ffmpeg_path):
            display.advance_file("å¤±è´¥", "éŸ³é¢‘æå–å¤±è´¥")
            return False
        audio_mb = os.path.getsize(audio_path) / 1024 / 1024
        display.advance_file("è¯†åˆ«ä¸­", f"éŸ³é¢‘ {audio_mb:.1f}MB")

        # Step 2: Whisper è¯†åˆ«
        result = model.transcribe(audio_path, language=language, verbose=False)
        segments = result.get("segments", [])
        detected_lang = result.get("language", language)

        if not segments:
            display.advance_file("æ— å†…å®¹", "æœªæ£€æµ‹åˆ°è¯­éŸ³")
            return False

        # Step 3: ç¹è½¬ç®€
        def _cv(text):
            return converter.convert(text) if converter and text else text

        text_lines = [_cv(seg["text"].strip()) for seg in segments if seg.get("text", "").strip()]
        tag = "â†’ç®€" if converter else ""
        display.advance_file("ä¿å­˜", f"{len(segments)}æ®µ lang={detected_lang} {tag}")

        # Step 4: å†™æ–‡ä»¶
        saved = []
        if "txt" in output_formats:
            txt_path.write_text("\n".join(text_lines), encoding="utf-8")
            saved.append(txt_path.name)
        if "srt" in output_formats:
            srt_lines = []
            for i, seg in enumerate(segments, 1):
                text = _cv(seg["text"].strip())
                if text:
                    srt_lines.append(
                        f"{i}\n{_format_srt_time(seg['start'])} --> {_format_srt_time(seg['end'])}\n{text}\n"
                    )
            srt_path.write_text("\n".join(srt_lines), encoding="utf-8")
            saved.append(srt_path.name)

        display.advance_file("å®Œæˆ", " + ".join(saved))
        return True

    finally:
        shutil.rmtree(tmpdir, ignore_errors=True)


def find_videos(directory, skip_existing=False):
    directory = Path(directory)
    if not directory.exists():
        display.error(f"ç›®å½•ä¸å­˜åœ¨: {directory}")
        return []

    videos = sorted(directory.rglob("*.mp4"))

    if skip_existing:
        filtered = []
        for v in videos:
            txt2 = v.parent / f"{v.stem}.transcript.txt"
            if txt2.exists():
                display.info(f"è·³è¿‡ {v.name} (å·²æœ‰transcript)")
            else:
                filtered.append(v)
        videos = filtered

    return videos


# ============================================================
# Main
# ============================================================
def main():
    parser = argparse.ArgumentParser(
        description="Whisper è§†é¢‘è½¬å½•å·¥å…· â€” æ‰¹é‡è¯­éŸ³è¯†åˆ«",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog=(
            "ç¤ºä¾‹:\n"
            "  python whisper_transcribe.py -d ./Downloaded/\n"
            "  python whisper_transcribe.py -f video.mp4 -m medium\n"
            "  python whisper_transcribe.py -d ./Downloaded/ --srt --sc --skip-existing"
        ),
    )
    parser.add_argument("-d", "--dir", default="./Downloaded", help="è§†é¢‘ç›®å½• (é»˜è®¤ ./Downloaded/)")
    parser.add_argument("-f", "--file", help="å•ä¸ªè§†é¢‘æ–‡ä»¶")
    parser.add_argument("-m", "--model", default="base",
                        choices=["tiny", "base", "small", "medium", "large"],
                        help="Whisperæ¨¡å‹ (é»˜è®¤ base)")
    parser.add_argument("-l", "--language", default="zh", help="è¯­è¨€ (é»˜è®¤ zh)")
    parser.add_argument("--srt", action="store_true", help="åŒæ—¶è¾“å‡ºSRTå­—å¹•")
    parser.add_argument("--skip-existing", action="store_true", help="è·³è¿‡å·²æœ‰transcriptçš„è§†é¢‘")
    parser.add_argument("--sc", action="store_true", help="ç¹ä½“è½¬ç®€ä½“ (éœ€ pip install OpenCC)")

    args = parser.parse_args()

    # â”€â”€ Banner â”€â”€
    display.show_banner()

    # â”€â”€ ä¾èµ–æ£€æŸ¥ â”€â”€
    console.print(f"  [{THEME['dim']}]æ£€æŸ¥ä¾èµ–...[/]")

    ffmpeg_path = find_ffmpeg()
    if not ffmpeg_path:
        display.dep_fail("ffmpeg", "conda install -c conda-forge ffmpeg  æˆ–æ”¾ ffmpeg.exe åˆ°åŒç›®å½•")
        sys.exit(1)
    display.dep_ok("ffmpeg", ffmpeg_path)

    try:
        import whisper
    except ImportError:
        display.dep_fail("openai-whisper", "pip install openai-whisper")
        sys.exit(1)
    display.dep_ok("whisper", "å·²å®‰è£…")

    converter = None
    if args.sc:
        try:
            from opencc import OpenCC
            converter = OpenCC('t2s')
            display.dep_ok("OpenCC", "ç¹ä½“â†’ç®€ä½“")
        except ImportError:
            display.dep_fail("OpenCC", "pip install OpenCC")
            sys.exit(1)

    console.print()

    # â”€â”€ æ”¶é›†è§†é¢‘ â”€â”€
    if args.file:
        videos = [Path(args.file)]
        if not videos[0].exists():
            display.error(f"æ–‡ä»¶ä¸å­˜åœ¨: {args.file}")
            sys.exit(1)
    else:
        videos = find_videos(args.dir, skip_existing=args.skip_existing)

    if not videos:
        display.warning("æ²¡æœ‰æ‰¾åˆ°éœ€è¦å¤„ç†çš„è§†é¢‘æ–‡ä»¶")
        return

    display.info(f"æ‰¾åˆ° {len(videos)} ä¸ªè§†é¢‘")

    # â”€â”€ åŠ è½½æ¨¡å‹ â”€â”€
    display.info(f"åŠ è½½ Whisper æ¨¡å‹: [{THEME['model']}]{args.model}[/]  (é¦–æ¬¡éœ€ä¸‹è½½)")
    model = whisper.load_model(args.model)
    display.success(f"æ¨¡å‹ [{THEME['model']}]{args.model}[/] åŠ è½½å®Œæˆ")
    console.print()

    # â”€â”€ è¾“å‡ºæ ¼å¼ â”€â”€
    output_formats = {"txt"}
    if args.srt:
        output_formats.add("srt")

    # â”€â”€ å¤„ç† â”€â”€
    display.start_session(len(videos))
    try:
        for i, video in enumerate(videos, 1):
            display.start_file(i, video.name)
            try:
                ok = transcribe_file(video, model, ffmpeg_path, output_formats, args.language, converter)
                display.complete_file("success" if ok else "failed",
                                      video.name if ok else "è¯†åˆ«å¤±è´¥")
            except KeyboardInterrupt:
                display.complete_file("failed", "ç”¨æˆ·ä¸­æ–­")
                raise
            except Exception as e:
                display.complete_file("failed", str(e)[:60])
    except KeyboardInterrupt:
        display.warning("ç”¨æˆ·ä¸­æ–­")
    finally:
        display.stop_session()

    # â”€â”€ æ±‡æ€» â”€â”€
    display.show_summary()


if __name__ == "__main__":
    main()